{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "print(\"Let's a go!\")\n",
    "\n",
    "print(\"Connecting to weaviate instance on localhost:8080...\")\n",
    "client = weaviate.Client(\"http://localhost:8080\")\n",
    "print(\"Client created\")\n",
    "\n",
    "pprint.pprint(client.schema.get())\n",
    "\n",
    "result = (\n",
    "    client.query\n",
    "    .get(\"DriftBenchmark\", [\"prompt_token_len\", \"prompt_sent_len\", \"prompt\", \"completion_token_len\", \"completion_sent_len\", \"completion\", \"date_time\", \"chat_id\"])\n",
    "    .do()\n",
    ")\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import json\n",
    "\n",
    "print(\"Let's a go!\")\n",
    "\n",
    "print(\"Connecting to weaviate instance on localhost:8080...\")\n",
    "client = weaviate.Client(\"http://localhost:8080\")\n",
    "print(\"Client created\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "print(\"sbert loaded\")\n",
    "\n",
    "def process_query(vec):\n",
    "    where_filter = {\n",
    "        \"path\": [\"chat_id\"],\n",
    "        \"operator\": \"Equal\",\n",
    "        \"valueText\": \"c5f83121-758e-46b2-99d1-5ca0c6f59919\",\n",
    "    }\n",
    "    nearVector = {\"vector\": vec}\n",
    "    res = client.query.get(\"DriftBenchmark\", [\"chat_id\", \"prompt\", \"completion\", \"_additional {certainty, distance}\"]).with_near_vector(nearVector).with_where(where_filter).do()\n",
    "    print(\"------------------------------------------------------------------------------------------------\")\n",
    "    print(\"-----------------------------------Most similar text -------------------------------------------\")\n",
    "    print(\"ChatID: \", end='')\n",
    "    print(res['data']['Get']['DriftBenchmark'][0]['chat_id'], end='')\n",
    "    print(\", Prompt Token Count: \", end='')\n",
    "    print(res['data']['Get']['DriftBenchmark'][0]['prompt_token_len'], end='')\n",
    "    print(\", Prompt Sentences Count: \", end='')\n",
    "    print(res['data']['Get']['DriftBenchmark'][0]['prompt_sent_len'], end='')\n",
    "    print(\", Prompt: \", end='')\n",
    "    print(res['data']['Get']['DriftBenchmark'][0]['prompt'], end='')\n",
    "    print(\", Completion Token Count: \", end='')\n",
    "    print(res['data']['Get']['DriftBenchmark'][0]['prompt_token_len'], end='')\n",
    "    print(\", Completion Sentences Count: \", end='')\n",
    "    print(res['data']['Get']['DriftBenchmark'][0]['prompt_sent_len'], end='')\n",
    "    print(\", Completion: \", end='')\n",
    "    print(res['data']['Get']['DriftBenchmark'][0]['completion'], end='')\n",
    "    print(\", Certainty: \", end='')\n",
    "    print(res['data']['Get']['DriftBenchmark'][0]['_additional']['certainty'])\n",
    "    print(\", Distance: \", end='')\n",
    "    print(res['data']['Get']['DriftBenchmark'][0]['_additional']['distance'])\n",
    "    print(\"------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "print(\"Running a test query first...\")\n",
    "\n",
    "# this is exactly the text in cmpletion for \n",
    "#{\n",
    "#\"prompt\": \"how to create a custom shell using click and cmd\",\n",
    "#\"completion\": \"To create a custom shell using Click and Cmd, you can follow these steps:  1. Install the Click library by running `pip install click` in your terminal. 2. Import the necessary modules from Click and Cmd: ``` from click import Command, option, Argument from cmd import Cmd ``` 3. Create a new class that inherits from the Cmd class and override the necessary methods to handle user input and commands. For example, you can override the `do_command` method to handle specific commands that you want to\",\n",
    "#\"chat_id\": \"c5f83121-758e-46b2-99d1-5ca0c6f59919\"\n",
    "#}\n",
    "\n",
    "test_query = \"To create a custom shell using Click and Cmd, you can follow these steps:  1. Install the Click library by running `pip install click` in your terminal. 2. Import the necessary modules from Click and Cmd: ``` from click import Command, option, Argument from cmd import Cmd ``` 3. Create a new class that inherits from the Cmd class and override the necessary methods to handle user input and commands. For example, you can override the `do_command` method to handle specific commands that you want to\"\n",
    "query_vec = sbert_model.encode(test_query)\n",
    "print(query_vec)\n",
    "process_query(query_vec)\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Certainty: 0.9343259930610657\n",
    "\n",
    "# now shorten it by 20 chars\n",
    "test_query = \"To create a custom shell using Click and Cmd, you can follow these steps:  1. Install the Click library by running `pip install click` in your terminal. 2. Import the necessary modules from Click and Cmd: ``` from click import Command, option, Argument from cmd import Cmd ``` 3. Create a new class that inherits from the Cmd class and override the necessary methods to handle user input and commands. For example, you can override the `do_command` method to handle specific comma\"\n",
    "query_vec = sbert_model.encode(test_query)\n",
    "print(query_vec)\n",
    "process_query(query_vec)\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# 1 Certainty: 0.9343259930610657\n",
    "# 2 Certainty: 0.9157571196556091\n",
    "#  difference: 0.0185688734054566\n",
    "\n",
    "# 1 Distance: 0.13134801\n",
    "# 2 Distance: 0.16848576\n",
    "# difference: 0.03713775\n",
    "\n",
    "# while True:\n",
    "    \n",
    "#     query = input(\"Enter query:\")\n",
    "#     if query=='q':\n",
    "#         break\n",
    "\n",
    "#     query_vec = sbert_model.encode(query)\n",
    "#     #print(query_vec)\n",
    "#     process_query(query_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query with Cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import json\n",
    "\n",
    "print(\"Let's a go!\")\n",
    "\n",
    "print(\"Connecting source_client to weaviate instance on localhost:8080...\")\n",
    "source_client = weaviate.Client(\"http://localhost:8080\")\n",
    "print(\"source_client created\")\n",
    "\n",
    "limit = 10\n",
    "result_count = 0\n",
    "aggregate_count = 0\n",
    "batch_size = 5\n",
    "class_name = \"DriftBenchmark\"\n",
    "class_properties = [\"prompt\"]\n",
    "cursor = None\n",
    "\n",
    "def get_batch_with_cursor(client, class_name, class_properties, batch_size, cursor=None):\n",
    "\n",
    "    query = (\n",
    "        client.query.get(\"DriftBenchmark\", [\"chat_id\", \"prompt\", \"completion\"])\n",
    "        # Optionally retrieve the vector embedding by adding `vector` to the _additional fields\n",
    "        .with_additional([\"id vector\"])\n",
    "        .with_limit(batch_size)\n",
    "    )\n",
    "\n",
    "    if cursor is not None:\n",
    "        return query.with_after(cursor).do()\n",
    "    else:\n",
    "        return query.do()\n",
    "\n",
    "# Batch import all objects to the target instance\n",
    "while True:\n",
    "    \n",
    "    # From the SOURCE instance, get the next group of objects\n",
    "    results = get_batch_with_cursor(source_client, class_name, class_properties, batch_size, cursor)\n",
    "\n",
    "    # If empty, we're finished\n",
    "    if len(results[\"data\"][\"Get\"][class_name]) == 0:\n",
    "        break\n",
    "\n",
    "    # Otherwise, add the objects to the batch to be added to the target instance\n",
    "    objects_list = results[\"data\"][\"Get\"][class_name]\n",
    "    aggregate_count += len(objects_list)\n",
    "    \n",
    "    print('aggregate_count = {}'.format(aggregate_count))\n",
    "    \n",
    "    for res in objects_list:\n",
    "        # print(json.dumps(res, indent=4))\n",
    "        print(\"{}. {}\".format(result_count, res['completion']))\n",
    "        # res[\"data\"][\"Get\"]\n",
    "        result_count += 1\n",
    "        \n",
    "    if(aggregate_count >= limit):\n",
    "        break\n",
    "\n",
    "    # Update the cursor to the id of the last retrieved object\n",
    "    cursor = results[\"data\"][\"Get\"][class_name][-1][\"_additional\"][\"id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Run a weaviate query with a cursor, \n",
    "# one at a time, we send the benchmark prompt to cohere\n",
    "# and just print the completion response \n",
    "\n",
    "import weaviate\n",
    "import cohere\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('COHERE_API_KEY')\n",
    "\n",
    "def IsOkString(value):\n",
    "    if not value or len(value)==0:\n",
    "        return False \n",
    "    else:\n",
    "        return True\n",
    "\n",
    "print(\"Let's a go!\")\n",
    "\n",
    "print(\"Connecting source_client to weaviate instance on localhost:8080...\")\n",
    "source_client = weaviate.Client(\"http://localhost:8080\")\n",
    "print(\"source_client created\")\n",
    "\n",
    "# These are guardrails to prevent offending the free cohere API.\n",
    "limit = 3\n",
    "aggregate_count = 6\n",
    "batch_size = 7\n",
    "\n",
    "result_count = 0\n",
    "class_name = \"DriftBenchmark\"\n",
    "class_properties = [\"prompt\"]\n",
    "cursor = None\n",
    "\n",
    "print(\"Creating cohere_client\")\n",
    "cohere_client = cohere.Client(api_key) # This is your trial API key\n",
    "\n",
    "# you can add filters to this query - look in dev_nb\\03_weaviate_queries_dev.ipynb\n",
    "\n",
    "def wv_wv_get_batch_with_cursor(client, class_name, class_properties, batch_size, cursor=None):\n",
    "\n",
    "    query = (\n",
    "        client.query.get(\"DriftBenchmark\", [\"chat_id\", \"prompt\", \"completion\"])\n",
    "        # Optionally retrieve the vector embedding by adding `vector` to the _additional fields\n",
    "        .with_additional([\"id vector\"])\n",
    "        .with_limit(batch_size)\n",
    "    )\n",
    "\n",
    "    if cursor is not None:\n",
    "        return query.with_after(cursor).do()\n",
    "    else:\n",
    "        return query.do()\n",
    "\n",
    "\n",
    "print(\"Running the query...\")\n",
    "print_runtime()\n",
    "\n",
    "# Batch import all objects to the target instance\n",
    "while True:\n",
    "    \n",
    "    # From the SOURCE instance, get the next group of objects\n",
    "    results = wv_get_batch_with_cursor(source_client, class_name, class_properties, batch_size, cursor)\n",
    "\n",
    "    # If empty, we're finished\n",
    "    if len(results[\"data\"][\"Get\"][class_name]) == 0:\n",
    "        break\n",
    "\n",
    "    # Otherwise, add the objects to the batch to be added to the target instance\n",
    "    objects_list = results[\"data\"][\"Get\"][class_name]\n",
    "    aggregate_count += len(objects_list)\n",
    "    \n",
    "    print('aggregate_count = {}'.format(aggregate_count))\n",
    "    \n",
    "    for res in objects_list:\n",
    "        # print(json.dumps(res, indent=4))\n",
    "        \n",
    "        the_prompt = res['prompt']\n",
    "        print(\"\\n  Weaviate Benchmark sample #{}.\\n    Prompt: {}\\n    Completion: {}\".format(result_count, res['prompt'], res['completion']))\n",
    "        result_count += 1\n",
    "        \n",
    "        response = cohere_client.generate(\n",
    "            model='command',\n",
    "            prompt=the_prompt,\n",
    "            max_tokens=300,\n",
    "            temperature=0.9,\n",
    "            k=0,\n",
    "            stop_sequences=[],\n",
    "            return_likelihoods='NONE')\n",
    "        \n",
    "        # print the full response object:\n",
    "        # print(\"Cohere prompt response: {}\".format(response))\n",
    "        \n",
    "        prompt_response = response.generations[0].text.replace(\"\\n\", \" \")\n",
    "        print(\"\\n  Cohere completion:\\n    {}\".format(prompt_response))        \n",
    "        print(\"------------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    if(aggregate_count >= limit):\n",
    "        break\n",
    "\n",
    "    # Update the cursor to the id of the last retrieved object\n",
    "    cursor = results[\"data\"][\"Get\"][class_name][-1][\"_additional\"][\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Sentence Similarities\n",
    "\n",
    "The sentences (texts) are mapped such that sentences with similar meanings are close in vector space. One common method to measure the similarity in vector space is to use [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity). For two sentences, this can be done like this:\n",
    "\n",
    "Note: the model we'll (multi-qa-MiniLM-L6-cos-v1) use must be the same one we used to create the original DriftBenchmark import.\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "emb1 = model.encode(\"To create a custom shell using Click and Cmd, you can follow these steps:  1. Install the Click library by running `pip install click` in your terminal. 2. Import the necessary modules from Click and Cmd: ``` from click import Command, option, Argument from cmd import Cmd\")\n",
    "\n",
    "emb2 = model.encode(\"To create a custom shell using Click and Cmd, you can follow these steps:  1. Install the Click library by running `pip install click` in your terminal.\")\n",
    "\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(\"Cosine-Similarity:\", cos_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `SentenceTransformer('all-MiniLM-L6-v2')` we define which sentence transformer model we like to load. In this example, we load *all-MiniLM-L6-v2*, which is a MiniLM model fine tuned on a large dataset of over 1 billion training pairs.\n",
    "\n",
    "BERT (and other transformer networks) output for each token in our input text an embedding. In order to create a fixed-sized sentence embedding out of this, the model applies mean pooling, i.e., the output embeddings for all tokens are averaged to yield a fixed-sized vector.\n",
    "\n",
    "## Comparing Sentence Similarities\n",
    "\n",
    "The sentences (texts) are mapped such that sentences with similar meanings are close in vector space. One common method to measure the similarity in vector space is to use [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity). For two sentences, this can be done like this:\n",
    "\n",
    "Note: the model we'll (multi-qa-MiniLM-L6-cos-v1) use must be the same one we used to create the original DriftBenchmark import.\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "emb1 = model.encode(\"To create a custom shell using Click and Cmd, you can follow these steps:  1. Install the Click library by running `pip install click` in your terminal. 2. Import the necessary modules from Click and Cmd: ``` from click import Command, option, Argument from cmd import Cmd\")\n",
    "\n",
    "emb2 = model.encode(\"To create a custom shell using Click and Cmd, you can follow these steps:  1. Install the Click library by running `pip install click` in your terminal.\")\n",
    "\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(\"Cosine-Similarity:\", cos_sim)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "vector1 = model.encode(\"The pizza is hot\")\n",
    "\n",
    "# the result of model.encode is a 384-dimension vector:\n",
    "# print(vector1)\n",
    "\n",
    "# identical sentences produce cosine similarity of 1.0\n",
    "emb1 = model.encode(\"The large dog is red\")\n",
    "emb2 = model.encode(\"The large dog is red\")\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(\"1 - Cosine-Similarity:\", cos_sim.item())\n",
    "\n",
    "# make a change that doesn't change the meaning too much\n",
    "# and the the cosine similarity decreases a small amount.\n",
    "emb1 = model.encode(\"The large dog is red\")\n",
    "emb2 = model.encode(\"The large canine is red\")\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(\"2 - Cosine-Similarity:\", cos_sim.item())\n",
    "\n",
    "# continue making small changes and watch the cosine similarity decrease.\n",
    "emb1 = model.encode(\"The large dog is red\")\n",
    "emb2 = model.encode(\"The big canine is red\")\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(\"3 - Cosine-Similarity:\", cos_sim.item())\n",
    "\n",
    "emb1 = model.encode(\"The large dog is red\")\n",
    "emb2 = model.encode(\"The big cat is red\")\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(\"4 - Cosine-Similarity:\", cos_sim.item())\n",
    "\n",
    "emb1 = model.encode(\"The large dog is red\")\n",
    "emb2 = model.encode(\"The big house is red\")\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(\"5 - Cosine-Similarity:\", cos_sim.item())\n",
    "\n",
    "# unrelated sentences produce cosine similarity closer to zero.\n",
    "emb1 = model.encode(\"The small rock is transparent\")\n",
    "emb2 = model.encode(\"Romeo, Romeo, wherefore are thou, Romeo\")\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(\"6 - Cosine-Similarity:\", cos_sim.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add the cosine_similarity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import cohere\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "def IsOkString(value):\n",
    "    if not value or len(value)==0:\n",
    "        return False \n",
    "    else:\n",
    "        return True\n",
    "\n",
    "print(\"Let's a go!\")\n",
    "\n",
    "print(\"Load the sentence transformer model: multi-qa-MiniLM-L6-cos-v1 \")\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "\n",
    "print(\"Connecting source_client to weaviate instance on localhost:8080...\")\n",
    "source_client = weaviate.Client(\"http://localhost:8080\")\n",
    "print(\"source_client created\")\n",
    "\n",
    "limit = 1\n",
    "result_count = 0\n",
    "aggregate_count = 0\n",
    "batch_size = 3\n",
    "class_name = \"DriftBenchmark\"\n",
    "class_properties = [\"prompt\"]\n",
    "cursor = None\n",
    "\n",
    "print(\"Creating cohere_client\")\n",
    "cohere_client = cohere.Client(api_key) # This is your trial API key\n",
    "\n",
    "\n",
    "def wv_get_batch_with_cursor(client, class_name, class_properties, batch_size, cursor=None):\n",
    "\n",
    "    query = (\n",
    "        client.query.get(\"DriftBenchmark\", [\"chat_id\", \"prompt\", \"completion\"])\n",
    "        # Optionally retrieve the vector embedding by adding `vector` to the _additional fields\n",
    "        .with_additional([\"id vector\"])\n",
    "        .with_limit(batch_size)\n",
    "    )\n",
    "\n",
    "    if cursor is not None:\n",
    "        return query.with_after(cursor).do()\n",
    "    else:\n",
    "        return query.do()\n",
    "\n",
    "\n",
    "print(\"Have fun storming the castle!\")\n",
    "\n",
    "# Batch import all objects to the target instance\n",
    "while True:\n",
    "    \n",
    "    # From the SOURCE instance, get the next group of objects\n",
    "    results = wv_get_batch_with_cursor(source_client, class_name, class_properties, batch_size, cursor)\n",
    "\n",
    "    # If empty, we're finished\n",
    "    if len(results[\"data\"][\"Get\"][class_name]) == 0:\n",
    "        break\n",
    "\n",
    "    # Otherwise, add the objects to the batch to be added to the target instance\n",
    "    objects_list = results[\"data\"][\"Get\"][class_name]\n",
    "    aggregate_count += len(objects_list)\n",
    "    \n",
    "    print('aggregate_count = {}'.format(aggregate_count))\n",
    "    \n",
    "    for res in objects_list:\n",
    "        the_prompt = res['prompt']\n",
    "        result_count += 1\n",
    "        \n",
    "        response = cohere_client.generate(\n",
    "            model='command',\n",
    "            prompt=the_prompt,\n",
    "            max_tokens=300,\n",
    "            temperature=0.9,\n",
    "            k=0,\n",
    "            stop_sequences=[],\n",
    "            return_likelihoods='NONE')\n",
    "                \n",
    "        completion = response.generations[0].text.replace(\"\\n\", \" \")\n",
    "        vec_current_completion = model.encode(completion)\n",
    "        cos_sim = util.cos_sim(res['_additional']['vector'], vec_current_completion)\n",
    "        print(\"Cosine-Similarity:\", cos_sim.item())\n",
    "        print(\"------------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    \n",
    "    if(aggregate_count >= limit):\n",
    "        break\n",
    "\n",
    "    # Update the cursor to the id of the last retrieved object\n",
    "    cursor = results[\"data\"][\"Get\"][class_name][-1][\"_additional\"][\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the baseline samples into sqlite db\n",
    "```sql\n",
    "sqlite3 database: driftDb\n",
    "\n",
    "INSERT INTO tSample (\n",
    "                        chat_id,\n",
    "                        sample_dt,\n",
    "                        cos_sim,\n",
    "                        completion\n",
    "                    )\n",
    "                    VALUES (\n",
    "                        'chat_id',\n",
    "                        'sample_dt',\n",
    "                        'cos_sim',\n",
    "                        'completion'\n",
    "                    );\n",
    "```\n",
    "\n",
    "Set these as appropriate\n",
    "5 and 10 is good for dev\n",
    "```python\n",
    "batch_size = 5  \n",
    "limit = 10\n",
    "```\n",
    "20 and 1000 is good when ur ready to go\n",
    "should only need 20 seconds.\n",
    "```python\n",
    "batch_size = 20  \n",
    "limit = 1000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import sqlite3\n",
    "\n",
    "print(\"Connecting source_client to weaviate instance on localhost:8080...\")\n",
    "source_client = weaviate.Client(\"http://localhost:8080\")\n",
    "print(\"source_client created\")\n",
    "\n",
    "print(\"Connecting to sqlite driftDb\")\n",
    "DRIFT_DB_PATH = \"..\\\\data\\\\driftDb.db\"\n",
    "con = sqlite3.connect(DRIFT_DB_PATH)\n",
    "sql_cursor = con.cursor()\n",
    "\n",
    "runtime = datetime.datetime.now().replace(second=0, microsecond=0)\n",
    "\n",
    "# sql\n",
    "def sql_insert_sample(chat_id, cos_sim, completion):\n",
    "    sql = \"INSERT INTO tSample (chat_id, run_time, cos_sim, completion ) VALUES ('{}', '{}', '{}', \\\"{}\\\");\".format(chat_id, runtime, cos_sim, completion)\n",
    "    print(sql)\n",
    "    sql_cursor.execute(sql)\n",
    "    con.commit()  \n",
    "    \n",
    "batch_size = 20  \n",
    "limit = 1000\n",
    "result_count = 0\n",
    "aggregate_count = 0\n",
    "\n",
    "class_name = \"DriftBenchmark\"\n",
    "class_properties = [\"prompt\"]\n",
    "cursor = None\n",
    "\n",
    "#weaviate\n",
    "def wv_get_batch_with_cursor(client, class_name, class_properties, batch_size, cursor=None):\n",
    "\n",
    "    query = (\n",
    "        client.query.get(\"DriftBenchmark\", [\"chat_id\", \"prompt\", \"completion\"])\n",
    "        # Optionally retrieve the vector embedding by adding `vector` to the _additional fields\n",
    "        .with_additional([\"id vector\"])\n",
    "        .with_limit(batch_size)\n",
    "    )\n",
    "\n",
    "    if cursor is not None:\n",
    "        return query.with_after(cursor).do()\n",
    "    else:\n",
    "        return query.do()\n",
    "\n",
    "# Batch import all objects to the target instance\n",
    "while True:\n",
    "    \n",
    "    # From the SOURCE instance, get the next group of objects\n",
    "    results = wv_get_batch_with_cursor(source_client, class_name, class_properties, batch_size, cursor)\n",
    "\n",
    "    # If empty, we're finished\n",
    "    if len(results[\"data\"][\"Get\"][class_name]) == 0:\n",
    "        break\n",
    "\n",
    "    # Otherwise, add the objects to the batch to be added to the target instance\n",
    "    objects_list = results[\"data\"][\"Get\"][class_name]\n",
    "    aggregate_count += len(objects_list)\n",
    "    \n",
    "    print('aggregate_count = {}'.format(aggregate_count))\n",
    "    \n",
    "    for res in objects_list:\n",
    "        # print(json.dumps(res, indent=4))\n",
    "        print(\"{}. {}\".format(result_count, res['completion']))\n",
    "        # res[\"data\"][\"Get\"]\n",
    "        result_count += 1\n",
    "        \n",
    "        # insert benchmark baseline samples\n",
    "        sql_insert_sample(res['chat_id'], 1.0, res['completion']) \n",
    "        \n",
    "    if(aggregate_count >= limit):\n",
    "        break\n",
    "\n",
    "    # Update the wv cursor to the id of the last retrieved object\n",
    "    cursor = results[\"data\"][\"Get\"][class_name][-1][\"_additional\"][\"id\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
